/usr/bin/mysqladmin -u root password 'new-password'
/usr/bin/mysqladmin -u root password root
/usr/bin/mysqladmin -u root -h localhost.localdomain password 'new-password'

datadir=/var/lib/mysql --pid-file=/var/lib/mysql/localhost.localdomain.pid

创建tb表语句
create table tb(id int(4) auto_increment, name varchar(5), dept varchar(5), primary key(id))ENGINE=MyISAM AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;

主键索引(不能是null)

单值索引
create index dept_index on tb(dept);
唯一索引 (可以是null)
create unique index name_index on tb(name);
复合索引
create index dept_name_index on tb(dept,name);


单值索引
alter table tb add index dept_index on tb(dept);
唯一索引
alter table tb add unique index name_index(name);
复合索引
alter table tb add index dept_name_index(dept,name);

删除索引
drop index 索引名 on 表名;
drop index name_index on tb;

查询索引
show index from tb;

create table course(cid int(3), cname varchar(20), tid int(3) );
create table teacher(tid int(3), tname varchar(20), tcid int(3) );
create table teacherCard( tcid int(3), tcdesc varchar(200) );


insert into course values(1, 'java', 1);
insert into course values(2, 'html', 1);
insert into course values(3, 'sql', 2);
insert into course values(4, 'web', 3);

insert into teacher values(1, 'tz', 1);
insert into teacher values(2, 'tw', 2);
insert into teacher values(3, 'tl', 3);

insert into teacherCard values(1, 'tzdesc');
insert into teacherCard values(2, 'twdesc');
insert into teacherCard values(3, 'tldesc');

1)数据量小的表，优先查询
explain select * from teacher t, course c, teacherCard tc
where t.tid = c.tid and t.tcid = tc.tcid
and (c.cid = 2 or tc.tcid = 3);


id值不同时，id值越大越优先查询
将多表查询，转为子查询
explain select tc.tcdesc from teacherCard tc, course c, teacher t where c.tid = t.tid and t.tcid = tc.tcid and c.cname = 'sql'

explain select tc.tcdesc from teacherCard tc where tc.tcid = (select t.tcid from teacher t where t.tid = (select c.tid from course c where c.cname = 'sql'));

id值有相同有不同，id值越大越优先；id相同，从上往下顺序执行
explain select t.tname, tc.tcdesc from teacher t, teacherCard tc where t.tcid = tc.tcid and t.tid = (select c.tid from course c  where c.cname = 'sql');

2)查询类型
primary: 包含子查询的SQL中，最外层
subquery: 包含子查询的SQL中，非最外层
simple简单查询：不包含子查询和union
derived衍生查询
explain select cr.cname from (select * from course where tid in (1,2)) cr;

3)type：索引类型
 system>const>eq_ref>ref>range>index>all 对索引类型优化的前提：一定要有索引
其中: system, const只是理想情况(只查到一条数据)；实际能达到 ref或range

system, const 只查到一条数据
eq_ref 唯一性索引 每条数据有且只有一条（不能多也不能是0）

ref： 非唯一性索引，对于每个索引键，返回匹配的所有行(0, 多)
alter table teacher add index index_name (tname);
explain select * from teacher where tname = 'tz'

range：检索指定范围的行，where后面是范围查询 (between, in ,> ,<) in有时候会失效转为无索引(all
alter table teacher add index tid_index (tid);
explain select t.* from teacher t where t.tid in (1,2) ;
alter table teacher add index uk_tcid (tcid);

index: 查询全部索引中数据
explain select tid from teacher; --tid就是索引

all：查询表中全部数据
explain select cid from course; --cid不是索引

4)possible_keys 预测使用到的索引，有时是不准的

5)key 实际使用到的索引

6)key_len 索引的长度

7) ref：于type中的ref有区别。指明当前表所参照的字段

8) rows: 被索引优化查询的数据个数

9) Extra:

using filesort: 性能消耗大; 需要 “额外”的一次排序
对于单索引，如果排序和查找的是同一个字段，则不会出现using filesort。不同字段则会出现using filesort
建议：where哪些字段就order by哪些字段

对于复合索引：where和order by不要跨列也不要无序使用

using index: 性能提升，覆盖索引

using where: 需要回表查询
假设age是索引列
语句是 select age, name from table where age = 30 此语句必须回原表查询name

impossible where: where 子句永远为false
select * from table where a1 = 'x' and a1 = 'y';

SQL优化主要就是优化索引

编写过程：
select distinct .. from .. join .. on .. where .. group by.. having.. order by ..
解析过程：
from.. on.. join..where..group by...having .. select dintince .. order by

索引优化案例

1.
alter table test03 add index idx_a1_a2_a3_a4 (a1, a2, a3, a4);
explain select a1, a2, a3, a4 from test03 where a1 = 1 and a2 = 2 and a3 = 3 and a4 = 4; --执行的顺序和索引的顺序一致(推荐)
explain select a1, a2, a3, a4 from test03 where a4 = 1 and a3 = 2 and a2 = 3 and a1 = 4; --虽然编写顺序不一致，但是mysql默认优化器优化了sql
explain select a1, a2, a3, a4 from test03 where a1 = 1 and a2 = 2 and a4 = 4 order by a3;--以上sql用了a1, a2两个索引，回表查询a3
explain select a1, a2, a3, a4 from test03 where a1 = 1 and a4 = 4 order by a2, a3;--sql用了a1,一个索引，回表查询a2, a3
小结：如果(a, b, c, d)复合索引， 和使用的顺序全部一致则使用全部索引， 部分一致则使用部分，不跨列使用


单表，多表优化案例

单表---------------------------------------------------------
create table book(
bid int(4) PRIMARY key,
name varchar(20) not null,
authorid int(4) not null,
publicid int(4) not null,
typeid int(4) not null
);

insert into book VALUES(1, 'java', 1, 1, 2);
insert into book VALUES(2, 'tc', 2, 1, 2);
insert into book VALUES(3, 'wx', 3, 2, 1);
insert into book VALUES(4, 'math', 4, 2, 3);

select bid from book where typeid in (2, 3) and authorid=1;

优化：加索引
alter table book add index idx_bta(bid, typeid, authorid);

根据SQL实际解析的顺序，调整索引的顺序：
alter table book add index idx_tab (typeid, authorid, bid);

再次优化（之前是index级别）思路， 因为范围in有时候会实现，所以更换索引typeid，authorid的顺序
alter table book add index idx_atb (authorid, typeid, bid);

SQL中把范围查询typeid放在后面
explain select bid from book where authorid=1 and typeid in (2, 3) order by typeid desc;

--原则：把where后面的条件放在前面，select的字段放在后面。条件in的字段放在=的后面


两张表---------------------------------------------------------
create table teacher2(
tid int(4) primary key,
cid int(4) not null
);

create table course2(
cid int(4),
cname varchar(20)
);

insert into teacher2 values(1,2);
insert into teacher2 values(2,1);
insert into teacher2 values(3,3);

insert into course2 values(1, 'java');
insert into course2 values(2, 'python');
insert into course2 values(3, 'kotlin');

select * from teacher2 t left outer join course2 c on t.cid=c.cid where c.cname = 'java';

索引往哪张表里面加？ ---小表驱动大表
		     ---索引建立在经常使用的字段上 （本题 t.cid使用频繁，因此给该字段加索引）
		     ---左外链接给左表加索引，右外链接给右表加索引

小表：10条数据
大表：300条数据
select ...where 小表.x = 大表.x (将数据量小的表放在外层遍历)

alter table teacher2 add index index_teacher2_cid(cid);
alter table course2 add index index_course2_cname(cname);

Using join buffer: extra中的一个选项，作用 mysql引擎使用了连接缓存



三张表---------------------------------------------------------

三张表优化A B C
a.小表驱动大表 b.索引建立在经常查询的字段 


7.避免索引失效的一些原则
 (1)复合索引	
 a复合索引 不要跨列或无序使用
 order by(a,b,c) 不要order by(a,c,b)
 b复合索引，尽量使用全索引匹配
 (a,b,c)

 (2)不要再索引上进行任何操作 (计算，函数，类型转换) 否则索引失效
 select ..where A.x = ..; 不要 select ..where A.x*3 = ..;
 对于复合索引，如果左边失效，右边同时失效

 (3)复合索引不能使用不等于 !=, <>, is null,is not null。否则全部失效

索引优化成功与否是一个概率的问题：

1)---------索引优化，是一个大部分情况成功的事，但由于sql优化器的存在，结果不会百分之百被优化
2)---------一般来说，范围查询(<， >, in) 之后的索引失效
3)---------补救：尽量使用索引覆盖 (using index)
索引(a,b,c)
select a,b,c from xx.. where a=.. and b=..
4)---------like尽量以常量开头，不要以 %开头，否则索引失效。如果必须使用 like '%x%'查询，可以用索引覆盖挽救一部分
5)---------尽量不要使用类型转换(显示，隐式) 否则索引失效
explain select * from teacher where tname = 'abc' ---有效
explain select * from teacher where tname = 123 ---失效 程序底层将123转为 '123'
6)---------尽量不要使用or 否则索引失效

8.一些其他的优化方法
(1)exist和in
select ..from table where exist/in ( 子查询);
如果主查询数据集大，使用in
如果子查询数据集大，使用exists
	
exist语法：将主查询的结果，放到子查询结果中进行校验,如果有数据则校验成功。如果没数据返回空集
select tname from teacher where exists (select * from teacher);---校验成功
	
select tname from teacher where exists (select * from teacher where tid = 9999);---空集

(2)order by 优化
using filesort 有两种算法：双路排序，单路排序
mysql4.1版本之后，默认使用单路排序
使用单路排序，如果数据量大，可以将数据库默认的buffer改成1024 set max_length_for_sort_data = 1024;

提高order by查询的策略
a. 选择使用单路，双路。调整buffer大小
b. 避免select * ...
c. 复合索引，不要跨列使用，避免using filesort
d. 保证全部的排序字段 排序的一致性(都是升序或者降序)

9.SQL排序 - 慢查询日志：MYSQL提供的一种日志记录，用于记录MYSQL中响应时间超过阀值的SQL语句 (long_query_time) 10秒
	    慢查询日志默认是关闭的，建议开发时打开， 上线时关闭。
检查是否开启了慢查询日志：show variables like '%slow_query_log%';

临时开启 set global slow_query_log = 1; (0,关闭 1，开启)

永久开启 /etc/my.cnf 中追加配置
slow_query_log=1
slow_query_log_file=/var/lib/mysql/localhost-slow.log

慢查询阀值 show variables like '%long_query_time%';
设置临时阀值 set global lone_query_time = 5; ---设置完成后，重新登录起效
永久设置阀值 /etc/my.cnf中追加配置 long_query_time=5;

vim /var/lib/mysql/localhost-slow.log

获取记录数最多的3个SQL
mysqldumpslow -s r -t 3 /var/lib/mysql/localhost-slow.log
获取访问次数最多的3个SQL
mysqldumpslow -s c -t 3 /var/lib/mysql/localhost-slow.log
按时间排序，前10条包含left join查询语句的SQL
mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/localhost-slow.log

10.分析海量数据
create database testdata;

create table dept(
dno int(5) primary key DEFAULT 0,
dname varchar(20) not null default '',
loc varchar(30) default ''
) engine=innodb default charset=utf8;

create table emp(
eid int(5) primary key,
ename varchar(20) not null default '',
job varchar(20) not null default '',
deptno int(5) not null default 0
)engine=innodb default charset=utf8;

1.利用存储函数插入海量数据
如果报错：his function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you *might* want to use the less safe log_bin_trust_function_creators variable)
执行下面两个语句log_bin_trust_function_creators 把改成1
show variables like '%log_bin_trust_function_creators%';
set global log_bin_trust_function_creators = 1;

delimiter $
create function randstring(n int) returns varchar(255)
	begin
		declare all_str varchar(100) default 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';
		declare return_str varchar(255) default '';
		declare i int default 0;
		while i<n
		do
			set return_str = concat(return_str, substring(all_str, rand()*52, 1) );
			set i = i+1;
		end while;
		return return_str;
		
	end $
	
create function ran_num() returns int(5)
begin
	declare i int default 0;
	set i=floor( rand()*100);
	return i;
end $

create procedure insert_emp( in eid_start int(10), in data_times int(10))
begin
	declare i int default 0;
	set autocommit = 0;
	repeat
		insert into emp values(eid_start+i, randstring(5), 'other', ran_num()) ;
		set i=i+1;
		until i = data_times
	end repeat;
	commit;
	
end $

create procedure insert_dept( in dno_start int(10), in data_times int(10))
begin
	declare i int default 0;
	set autocommit = 0;
	repeat
		insert into dept values(dno_start+i, randstring(6), randstring(8)) ;
		set i=i+1;
		until i = data_times
	end repeat;
	commit;
	
end $

把终止符改回改回 delimiter ;

call insert_emp(1000, 800000);
call insert_dept(10, 30);

2.分析海量数据：profiles
(1)
show profiles;
show variables like '%profiling%';
set profiling = on;

show profiles;记录打开之后的所有SQL语句

(2)精确分析 sql诊断
show profile all for query 上一步查询的query_Id
show profile cpu, block io for query 上一步查询的query_Id

(3)全局查询日志 记录开启之后 全部SQL语句

show variables like '%general_log%';

-------将所有SQL记录在表中
set global general_log = 1; -------开启全局日志
set global log_output='table'; -------将所有SQL记录在表中

-------将所有SQL记录在文件中
set global log_output='file';
set global general_log = on;
set global general_log_file = '/tmp/general.log';

select * from mysql.general_log;

11.锁机制 解决因资源共享 而造成的并发问题

操作类型：
读锁(共享锁)：对同一个数据，多个读操作可以同时进行，互不干扰。
写锁(互斥锁)：如果当前写操作没有完毕，则无法进行其他的读操作，写操作。

操作范围：
表锁：一次性针对一张表整体加锁。如MyISAM存储引擎使用表锁，开销小，加锁快；无死锁；但锁的范围大，容易发生锁冲突，并发度低。
行锁：一次性对一条数据加锁。如InnoDB引擎使用行锁，开销大，加锁慢；容易发生死锁；锁的范围较小，不容易发生锁冲突，并发度高。
页锁

示例：
1. 表锁：
create table tablelock
(
id int primary key auto_increment,
name varchar(20)
)engine myisam;

insert into tablelock(name) values('a1');
insert into tablelock(name) values('a2');
insert into tablelock(name) values('a3');
insert into tablelock(name) values('a4');
insert into tablelock(name) values('a5');
加锁
lock table 表名 read/write
查看加锁的表
show open tables;

--------------------------加读锁
---当前会话：
lock table tablelock read;
在当前会话可以读，但不可以写(增删改)
select * from tablelock;
如果给A表加了读锁，当前会话只能对A表进行读操作，其他都干不了。
delete from tablelock where id = 1;
当前会话对于其他表，读写都不可以。

---其他会话：
在其他会话可以读，
select * from tablelock;
如果给A表加了读锁，其他会话进行写操作会一直等待，直到锁释放
delete from tablelock where id = 1;
其他会话对于其他表，读可以，写可以。

--------------------------加写锁
---当前会话：
lock table tablelock write;
当前会话对于加了写锁的表可以进行任何操作(增删改查)，但不能操作其他表。
---其他会话：
对于加了写锁表进行操作，都会一直等待，直到锁释放。

---释放锁
unlock tables;

分析表锁定：
查看哪些表加了锁：show open tables;
分析表锁定的严重程度：show status like 'table%'; Table_locks_immediate 即刻能获取到的锁数 Table_locks_waited 需要等待的表锁数

2. 行锁：
create table linelock
(
id int primary key auto_increment,
name varchar(20)
)engine myisam;

insert into linelock(name) values('1');
insert into linelock(name) values('2');
insert into linelock(name) values('3');
insert into linelock(name) values('4');
insert into linelock(name) values('5');

行锁通过事务解锁（commit）

12. 主从复制 (集群的一种实现方式)
安装windows版本mysql
先卸载mysql
删除缓存文件夹 C:\Users\Admin\AppData\Local\mysql  C:\ProgramData\mysql
删除注册表 regedit中所有mysql相关配置
--重启计算机

实现主从同步(主从复制) 

核心：通过二进制日志同步 binary log
1.master将改变的数据 记录在本地的binary log中(二进制日志事件)
2.slave将master的binary log拷贝的自己的relay log(中继日志文件)
3.中继日志事件，将数据读取到自己的数据库中

mysql主从复制: 异步的，串行化，有延迟

配置：
windows(mysql: my.ini) master
linux  (mysql: my.cnf) slave

配置前，先关闭防火墙，允许远程访问

grant all privileges on *.* to 'root'@'%' identified by 'root' with grant option;
flush privileges;


配置主机 windows(mysql: my.ini) master
[mysqld]
#id
server-id=1
#二进制日志文件(注意使用/)
log-bin="E:/MySQL/MySQL Server 5.5/data/mysql-bin"
#错误记录文件
log-error="E:/MySQL/MySQL Server 5.5/data/mysql-error"
#主从同步时，忽略的数据库
binlog-ignore-db=mysql
#(可选)主从同步时，同步哪些数据库
binlog-do-db=test

主数据库选择授权哪台计算机中的数据库，作为从数据库
GRANT REPLICATION slave, reload, super ON *.* TO 'root'@'192.168.14.35' IDENTIFIED BY 'root';
GRANT REPLICATION slave, reload, super ON *.* TO 'root'@'192.168.30.120' IDENTIFIED BY 'root';
flush privileges;

查看主数据库的状态(每次做主从同步前，需要观察主机状态的最新值)
show master status;
File: mysql-bin.000001 
Position: 107




配置从机 linux  (mysql: my.cnf) slave
[mysqld]
server-id=2
log-bin=mysql-bin
replicate-do-db=test

从数据库选择授权哪台计算机中的数据库，作为主数据库
CHANGE MASTER TO
MASTER_HOST = '192.168.14.35',
MASTER_USER = 'root',
MASTER_PASSWORD = 'root',
MASTER_PORT = 3306,
master_log_file = 'mysql-bin.000001',
master_log_pos = 349;
如果报错 This operation cannot be performed with a running slave;
先执行STOP SLAVE;

slave开启主从同步
START SALVE;
show slave status \G

观察下列参数，确保都是yes
Slave_IO_Running
Slave_SQL_Running
如果不都是yes，看下方日志Last_IO_Error
The slave I/O thread stops because master and slave have equal MySQL server ids
使用 show variables like 'server_id'; 发现都是1 有可能是linux和windows安装的版本不同导致的bug
解决bug，手动修改server_id：set global server_id = 2; 
之后stop slave; start slave;

在test数据库中创建表
create table tb1(
id int(4) primary key, 
name varchar(20) not null);

insert into tb1 values (1, 'aaa');

主主复制
1. my.ini 增加下列配置

#id
server-id=1
#二进制日志文件(注意使用/)
log-bin="E:/MySQL/MySQL Server 5.5/data/mysql-bin"
#错误记录文件
log-error="E:/MySQL/MySQL Server 5.5/data/mysql-error"
#主从同步时，忽略的数据库
binlog-ignore-db=mysql
#(可选)主从同步时，同步哪些数据库
binlog-do-db=mastertest

#主-主需加入的部分
replicate-do-db = mastertest
replicate-ignore-db=mysql,information_schema,test
log-slave-updates
sync_binlog=1
auto_increment_offset=1
auto_increment_increment=2

grant replication slave on *.* to 'repl'@'192.168.30.120' identified by '123456';
flush privileges;

2. 查看主数据库的状态(每次做主从同步前，需要观察主机状态的最新值)
show master status;

3. 选择主数据库
CHANGE MASTER TO
MASTER_HOST = '192.168.30.120',
MASTER_USER = 'root',
MASTER_PASSWORD = 'root',
MASTER_PORT = 3306,
master_log_file = 'mysql-bin.000009',
master_log_pos = 107;

如果报错 This operation cannot be performed with a running slave;
先执行STOP SLAVE;

slave开启主从同步
START SALVE;
show slave status \G

1.my.cnf 增加下列配置
[mysqld]
server-id=2
replicate-do-db = mastertest
#主-主需加入的部分
auto_increment_offset=2
auto_increment_increment=2
log-slave-updates
sync_binlog=1
log_bin = /var/lib/mysql/mysql-binlog
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=test
binlog_do_db = mastertest
replicate-ignore-db=mysql,information_schema

grant replication slave on *.* to 'repl'@'192.168.14.35' identified by '123456';
flush privileges;

2. 查看主数据库的状态(每次做主从同步前，需要观察主机状态的最新值)
show master status;

3. 从数据库选择授权哪台计算机中的数据库，作为主数据库

CHANGE MASTER TO
MASTER_HOST = '192.168.14.35',
MASTER_USER = 'root',
MASTER_PASSWORD = 'root',
MASTER_PORT = 3306,
master_log_file = 'mysql-bin.000001',
master_log_pos = 655;

如果报错 This operation cannot be performed with a running slave;
先执行STOP SLAVE;

slave开启主从同步
START SALVE;
show slave status \G

观察下列参数，确保都是yes
Slave_IO_Running
Slave_SQL_Running
如果不都是yes，看下方日志Last_IO_Error
The slave I/O thread stops because master and slave have equal MySQL server ids
使用 show variables like 'server_id'; 发现都是1 有可能是linux和windows安装的版本不同导致的bug
解决bug，手动修改server_id：set global server_id = 2; 
之后stop slave; start slave;

create table tb(
id int(4) primary key, 
name varchar(20) not null);


---------------mycat做读写分离--------------------


---------------schema.xml

<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
<schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100" dataNode="dn1">
<!-- 这里不配置，代表所有的表分片到dn1节点-->
</schema>
<dataNode name="dn1" dataHost="dataHost01" database="testms" />
<dataHost name="dataHost01" maxCon="1000" minCon="10" balance="1" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100">
<heartbeat>show slave status</heartbeat>
<!-- can have multi write hosts -->
<writeHost host="mysql_b1" url="127.0.0.1:3306" user="root" password="root">
<!-- can have multi read hosts -->
<readHost host="mysql_b2" url="192.168.30.120:3306" user="root" password="root" />
</writeHost>
</dataHost>
</mycat:schema>


---------------server.xml

<?xml version="1.0" encoding="UTF-8"?>
<!-- - - Licensed under the Apache License, Version 2.0 (the "License"); 
	- you may not use this file except in compliance with the License. - You 
	may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 
	- - Unless required by applicable law or agreed to in writing, software - 
	distributed under the License is distributed on an "AS IS" BASIS, - WITHOUT 
	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the 
	License for the specific language governing permissions and - limitations 
	under the License. -->
<!DOCTYPE mycat:server SYSTEM "server.dtd">
<mycat:server xmlns:mycat="http://io.mycat/">
	<system>
	<property name="nonePasswordLogin">0</property> <!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户-->
	<property name="useHandshakeV10">1</property>
	<property name="useSqlStat">0</property>  <!-- 1为开启实时统计、0为关闭 -->
	<property name="useGlobleTableCheck">0</property>  <!-- 1为开启全加班一致性检测、0为关闭 -->
		<property name="sqlExecuteTimeout">300</property>  <!-- SQL 执行超时 单位:秒-->
		<property name="sequnceHandlerType">2</property>
		<!--<property name="sequnceHandlerPattern">(?:(\s*next\s+value\s+for\s*MYCATSEQ_(\w+))(,|\)|\s)*)+</property>-->
		<!--必须带有MYCATSEQ_或者 mycatseq_进入序列匹配流程 注意MYCATSEQ_有空格的情况-->
		<property name="sequnceHandlerPattern">(?:(\s*next\s+value\s+for\s*MYCATSEQ_(\w+))(,|\)|\s)*)+</property>
	<property name="subqueryRelationshipCheck">false</property> <!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false -->
      <!--  <property name="useCompression">1</property>--> <!--1为开启mysql压缩协议-->
        <!--  <property name="fakeMySQLVersion">5.6.20</property>--> <!--设置模拟的MySQL版本号-->
	<!-- <property name="processorBufferChunk">40960</property> -->
	<!-- 
	<property name="processors">1</property> 
	<property name="processorExecutor">32</property> 
	 -->
        <!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool -->
		<property name="processorBufferPoolType">0</property>
		<!--默认是65535 64K 用于sql解析时最大文本长度 -->
		<!--<property name="maxStringLiteralLength">65535</property>-->
		<!--<property name="sequnceHandlerType">0</property>-->
		<!--<property name="backSocketNoDelay">1</property>-->
		<!--<property name="frontSocketNoDelay">1</property>-->
		<!--<property name="processorExecutor">16</property>-->
		<!--
			<property name="serverPort">8066</property> <property name="managerPort">9066</property> 
			<property name="idleTimeout">300000</property> <property name="bindIp">0.0.0.0</property>
			<property name="dataNodeIdleCheckPeriod">300000</property> 5 * 60 * 1000L; //连接空闲检查
			<property name="frontWriteQueueSize">4096</property> <property name="processors">32</property> -->
		<!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志-->
		<property name="handleDistributedTransactions">0</property>
		
			<!--
			off heap for merge/order/group/limit      1开启   0关闭
		-->
		<property name="useOffHeapForMerge">0</property>

		<!--
			单位为m
		-->
        <property name="memoryPageSize">64k</property>

		<!--
			单位为k
		-->
		<property name="spillsFileBufferSize">1k</property>

		<property name="useStreamOutput">0</property>

		<!--
			单位为m
		-->
		<property name="systemReserveMemorySize">384m</property>


		<!--是否采用zookeeper协调切换  -->
		<property name="useZKSwitch">false</property>

		<!-- XA Recovery Log日志路径 -->
		<!--<property name="XARecoveryLogBaseDir">./</property>-->

		<!-- XA Recovery Log日志名称 -->
		<!--<property name="XARecoveryLogBaseName">tmlog</property>-->
		<!--如果为 true的话 严格遵守隔离级别,不会在仅仅只有select语句的时候在事务中切换连接-->
		<property name="strictTxIsolation">false</property>
		
		<property name="useZKSwitch">true</property>
		
	</system>
	
	<!-- 全局SQL防火墙设置 -->
	<!-- 
	<firewall> 
	   <whitehost>
	      <host host="127.0.0.1" user="mycat"/>
	      <host host="127.0.0.2" user="mycat"/>
	   </whitehost>
       <blacklist check="false">
       </blacklist>
	</firewall>
	-->
	
	<user name="root">
		<property name="password">root</property>
		<property name="schemas">TESTDB</property>
		
		<!-- 表级 DML 权限设置 -->
		<!-- 		
		<privileges check="false">
			<schema name="TESTDB" dml="0110" >
				<table name="tb01" dml="0000"></table>
				<table name="tb02" dml="1111"></table>
			</schema>
		</privileges>		
		 -->
	</user>

	<user name="user">
		<property name="password">user</property>
		<property name="schemas">TESTDB</property>
		<property name="readOnly">true</property>
	</user>

</mycat:server>
